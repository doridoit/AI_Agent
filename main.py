import os
from dotenv import load_dotenv
load_dotenv()

import streamlit as st
import pandas as pd
import chardet
from modules import eda, anomaly_model
from modules.llm_selector import LLMManager
from modules.chatbot import ask_with_llm
from modules.chatbot_conversational_memory import create_memory_conversational_chain, extract_analysis_intent_and_column
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutTimeout


st.set_page_config(page_title="Data Analysis AI Agent", layout="wide")

st.title("ğŸ–¥ï¸ Data Analysis AI Agent")

llm_manager = LLMManager()

def read_file(file):
    if file.name.endswith('.csv'):
        rawdata = file.read()
        result = chardet.detect(rawdata)
        encoding = result['encoding']
        file.seek(0)  # Move the file pointer back to the beginning
        return pd.read_csv(file, encoding=encoding)
    elif file.name.endswith('.xlsx'):
        return pd.read_excel(file)

# 1. ë°ì´í„° ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (CSV, Excel)", type=["csv", "xlsx"])

if uploaded_file:
    df = read_file(uploaded_file)

    if df is None:
        st.stop()

    file_ext = os.path.splitext(uploaded_file.name)[1].lower()

    if file_ext == ".csv":
        st.write("ğŸ“Š ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ")
        st.dataframe(df)

    elif file_ext == ".xlsx":
        try:
            xls = pd.ExcelFile(uploaded_file)
            sheet_names = xls.sheet_names
            selected_sheet = st.selectbox("ğŸ“‘ ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”", sheet_names)
            df_preview = pd.read_excel(xls, sheet_name=selected_sheet, engine="openpyxl", nrows=10)
            st.write("ğŸ” ì‹œíŠ¸ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10í–‰)")
            st.dataframe(df_preview)

            start_row = st.number_input("ë°ì´í„°ê°€ ì‹œì‘ë˜ëŠ” í–‰ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (0ë¶€í„° ì‹œì‘)", min_value=0, value=0, step=1)

            if "load_clicked" not in st.session_state:
                st.session_state["load_clicked"] = False

            if st.button("ì´ ì‹œíŠ¸ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ë¶„ì„í•˜ê¸°"):
                st.session_state["load_clicked"] = True

            if st.session_state["load_clicked"]:
                try:
                    df_raw = pd.read_excel(xls, sheet_name=selected_sheet, engine="openpyxl", header=None)
                    df = df_raw.iloc[start_row:]
                    df = df.dropna(how='all')  # ì „ë¶€ NaNì¸ í–‰ ì œê±°
                    df.columns = [str(col) if pd.notna(col) else f"Unnamed_{i}" for i, col in enumerate(df.iloc[0])]
                    df = df[1:]  # ì»¬ëŸ¼ìœ¼ë¡œ ì“´ í–‰ ì œê±°
                    st.write("ğŸ“Š ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ")
                    st.dataframe(df)
                except Exception as e:
                    st.warning("Preprocessing failed: " + str(e))
                    df = None
        except Exception as e:
            st.error(f"Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            df = None


    # 2. EDA ë¶„ì„
    if df is not None:
        eda_type = st.radio("ğŸ“Œ EDA ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”", ("ì¼ë°˜í˜• EDA", "ë‹¤ë³€í˜• EDA"))


        if "run_eda_clicked" not in st.session_state:
            st.session_state["run_eda_clicked"] = False

        if st.button("EDA ë¶„ì„ ì‹¤í–‰"):
            st.session_state["run_eda_clicked"] = True

        if st.session_state["run_eda_clicked"]:
            if eda_type == "ì¼ë°˜í˜• EDA":
                eda.run_univariate_eda(df)
            elif eda_type == "ë‹¤ë³€í˜• EDA":
                eda.run_multivariate_eda(df)

    # 3. ì´ìƒíƒì§€
    st.subheader("ì´ìƒíƒì§€ ëª¨ë¸")
    selected_model = st.selectbox("ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”", ["Logistic Regression", "XGBoost", "AutoEncoder"])
            
    if st.button("ì´ìƒíƒì§€ ì‹¤í–‰"):
        result_df = anomaly_model.run_anomaly_detection(df, selected_model)
        st.dataframe(result_df)

    # 4. LLM Chatbot
    def show_chatbot_section(df):
        st.markdown("## LLM Chatbot")

        selected_provider = st.selectbox("ğŸ§  ì‚¬ìš©í•  LLM ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”", ["google:gemini-1.5-flash", "openai:gpt-3.5-turbo"])

        if st.button("LLM ì´ˆê¸°í™”"):
            result = llm_manager.init(selected_provider)
            if result == "ok":
                st.success(f"âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ ({selected_provider})")
            else:
                st.error(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {llm_manager.get_error()}")

        if "llm" not in st.session_state or selected_provider != st.session_state.get("last_loaded_model"):
            result = llm_manager.init(selected_provider)
            if result != "ok":
                st.error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {llm_manager.get_error()}")
                st.stop()
            st.session_state["llm"] = llm_manager.get_llm()
            st.session_state["last_loaded_model"] = selected_provider

        llm = st.session_state.get("llm")
        if llm:
            st.success("âœ… LLM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        import streamlit.components.v1 as components

        # ì»¤ìŠ¤í…€ CSSì™€ JSë¥¼ ì ìš©í•œ ì±„íŒ… ì…ë ¥ì°½
        st.markdown("""
        <style>
        .chat-input-container {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        .chat-input-box {
            flex-grow: 1;
        }
        .chat-message.user {
            text-align: right;
            color: #00BFFF;
            margin-bottom: 1em;
        }
        .chat-message.bot {
            text-align: left;
            color: #00FF7F;
            margin-bottom: 1em;
        }
        </style>
        <script>
        const inputBox = window.parent.document.querySelector('input[data-testid="stTextInput"]');
        if (inputBox) {
          inputBox.addEventListener("keydown", function(event) {
            if (event.key === "Enter") {
              const button = window.parent.document.querySelector('button[kind="secondary"]');
              if (button) button.click();
            }
          });
        }
        </script>
        """, unsafe_allow_html=True)

        with st.form("chat_form", clear_on_submit=True):
            user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="chat_input_form")
            submitted = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°")

        if submitted and user_input and 'df' in locals() and df is not None:
            try:
                df_preview = df.head(10).round(2).astype(str).to_string(index=False)
                chain = create_memory_conversational_chain(llm, df_preview)
                with ThreadPoolExecutor() as executor:
                    future = executor.submit(lambda: chain.invoke({
                        "df_preview": df_preview,
                        "history": "\n".join([]),
                        "input": user_input
                    }, config={"configurable": {"session_id": "default"}}))
                    try:
                        answer = future.result(timeout=15)
                        st.write("âœ… ì‘ë‹µ:", answer)
                    except FutTimeout:
                        st.error("â° LLM ì‘ë‹µì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë‚˜ ì§ˆë¬¸ì„ ë°”ê¿”ë³´ì„¸ìš”.")
            except Exception as e:
                import traceback
                st.error(f"âŒ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(traceback.format_exc())
        else:
            st.warning("ë°ì´í„°ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ê±°ë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        st.markdown("### ğŸ’¬ ì´ì „ ëŒ€í™”")
        from langchain_community.chat_message_histories import StreamlitChatMessageHistory
        msg_history = StreamlitChatMessageHistory()
        for msg in msg_history.messages:
            if msg.type == "human":
                st.markdown(f"<div class='chat-message user'>ğŸ‘¤ {msg.content}</div>", unsafe_allow_html=True)
            else:
                st.markdown(f"<div class='chat-message bot'>ğŸ¤– {msg.content}</div>", unsafe_allow_html=True)

        with st.expander("ğŸ“‚ Export Chat Logs"):
            if os.path.exists("logs/chat_log.csv"):
                with open("logs/chat_log.csv", "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ Download chat_log.csv",
                        data=f,
                        file_name="chat_log.csv",
                        mime="text/csv"
                    )
            else:
                st.info("No chat logs available yet.")

    show_chatbot_section(df)